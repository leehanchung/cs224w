{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "XCS224W_Colab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehanchung/cs224w/blob/main/notebooks/XCS224W_Colab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Colab 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this Colab, we will write the full pipeline for **learning node embeddings**.\n",
        "We will go through the following 3 steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   To start, we will load the familiar [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) from Colab 0. We will explore multiple graph statistics over this graph.\n",
        "2.   We will then work to transform the graph structure into a PyTorch tensor so that we can perform machine learning over the graph.\n",
        "\n",
        "3. Finally, we will write our first graph learning algorithm: a node embedding model. For simplicity, our model is simpler than the DeepWalk and node2vec algorithms taught in Module 1, Unit 1.2 - Node Embeddings. Nevertheless, it will still be rewarding and challenging, as we will write the whole procedure from scratch via PyTorch.\n",
        "\n",
        "Let's get started!\n",
        "\n",
        "**Note**: Make sure to **sequentially run all the cells** so that the intermediate variables / packages will carry over to the next cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1) Graph Basics\n",
        "To start, we load the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club), a classical graph in network science. As discussed in the introduction, we begin by exploring multiple graph statistics for this graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDkpByYYfSzb"
      },
      "source": [
        "## Setup\n",
        "As introduced in Colab 0, NetworkX is a powerful package for storing and manipluating graphs. We will heavily rely on NetworkX throughout this Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWPkJjPAfVNW"
      },
      "source": [
        "import networkx as nx\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqUnYT5qUZYh"
      },
      "source": [
        "## Zachary's karate club network\n",
        "\n",
        "The [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) is a social network graph of 34 members of a karate club, where links exist between members who have interacted outside the club."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIETqEfrfy5Y"
      },
      "source": [
        "G = nx.karate_club_graph()\n",
        "\n",
        "# G is an undirected graph\n",
        "type(G)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDvf3nm-ors4"
      },
      "source": [
        "# Visualize the graph\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  nx.draw(G, with_labels = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX25Y1CrYmgN"
      },
      "source": [
        "## Question 1: What is the average degree of the karate club network? (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUhES1VYo3tB"
      },
      "source": [
        "def average_degree(num_edges, num_nodes):\n",
        "  # TODO: Implement a function that takes the number of edges\n",
        "  # and number of nodes of a graph, and returns the average node degree of \n",
        "  # the graph. Round the result to nearest integer (for example \n",
        "  # 3.3 will be rounded to 3 and 3.7 will be rounded to 4).\n",
        "\n",
        "  avg_degree = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: Do not import any other Python package\n",
        "  ## 2: Do not use any function from NetworkX\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return avg_degree\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  num_edges = G.number_of_edges()\n",
        "  num_nodes = G.number_of_nodes()\n",
        "  avg_degree = average_degree(num_edges, num_nodes)\n",
        "  print(\"Average degree of karate club network is {}\".format(avg_degree))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk02fD4vYmZI"
      },
      "source": [
        "## Question 2: What is the average clustering coefficient of the karate club network? (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k15XKEto1aYJ"
      },
      "source": [
        "def average_clustering_coefficient(G):\n",
        "  # TODO: Implement a function that takes a nx.Graph\n",
        "  # and returns the average clustering coefficient. Round \n",
        "  # the result to 2 decimal places (for example 3.333 will\n",
        "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
        "\n",
        "  avg_cluster_coef = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: Please use the appropriate NetworkX clustering function\n",
        "  \n",
        "  # https://networkx.org/documentation/stable/reference/algorithms/clustering.html\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return avg_cluster_coef\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  avg_cluster_coef = average_clustering_coefficient(G)\n",
        "  print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zghQ-AhXYmP4"
      },
      "source": [
        "## Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)\n",
        "\n",
        "Please complete the code block by implementing the PageRank equation: $r_j^{t+1} = \\sum_{i \\rightarrow j} \\beta \\frac{r_i^t}{d_i} + (1 - \\beta) \\frac{1}{N}$ to update the PageRank value of an arbitrary node j for the first time step $t = 0 \\rightarrow t = 1$.\n",
        "\n",
        "**NOTE:** $r_j^0 = 1 / |G|$ for all nodes j (where $|G|$ is the number of nodes in the graph). Namely, at $t=0$ every node is initialized with the same PageRank value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOGdWjNc6O7x"
      },
      "source": [
        "def one_iter_pagerank(G, beta, r0, node_id):\n",
        "  # TODO: Implement a function that takes a nx.Graph, beta, r0 and node_id.\n",
        "  # For the given node_id = j, compute rj_1 as the PageRank of the input\n",
        "  # node j at time t = 1 (i.e. after ONE iteration). \n",
        "  # \n",
        "  # Round the result to 2 decimal places (for example 3.333 will\n",
        "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
        "  #\n",
        "  # NOTE: rj_0 = r0 for every node j (i.e. each node is initialized with \n",
        "  # the same PageRank value at t = 0; thus we do not need an initial PageRank\n",
        "  # vector r).\n",
        "\n",
        "  rj_1 = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: You should not use nx.pagerank!\n",
        "\n",
        "  \n",
        "  #########################################\n",
        "\n",
        "  return rj_1\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  beta = 0.8\n",
        "  r0 = 1 / G.number_of_nodes()\n",
        "  node = 0\n",
        "  r0_1 = one_iter_pagerank(G, beta, r0, node)\n",
        "  print(\"The PageRank value for node 0 after one iteration is {}\".format(r0_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icTcOULeYmIu"
      },
      "source": [
        "## Question 4: What is the (raw) closeness centrality for the karate club network node 5? (5 Points)\n",
        "\n",
        "The equation for closeness centrality is $c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v}$. Remember that we want the raw (unnormalized) closeness centrality form Module 1, Unit 1.1 - Traditional Feature Based Methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbCsq_tl-3ok"
      },
      "source": [
        "def closeness_centrality(G, node=5):\n",
        "  # TODO: Implement a function that calculates closeness centrality \n",
        "  # for a node in the karate club network. G is the input karate club \n",
        "  # network and 'node' is the node id of the node that we are interested\n",
        "  # in. Please round the closeness centrality result to 2 decimal places.\n",
        "\n",
        "  closeness = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note:\n",
        "  ## 1: You can use networkx closeness centrality function.\n",
        "  ## 2: Notice that networkx closeness centrality returns the normalized \n",
        "  ## closeness directly, which is different from the raw (unnormalized) \n",
        "  ## one that we learned in the lecture.\n",
        "\n",
        "  \n",
        "  #########################################\n",
        "\n",
        "  return closeness\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  node = 5\n",
        "  closeness = closeness_centrality(G, node=node)\n",
        "  print(\"The karate club network has closeness centrality {}\".format(closeness))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MxvowibYl4x"
      },
      "source": [
        "# 2) Graph to Tensor\n",
        "Now, we will work together to transform the graph $G$ into a PyTorch tensor, so that we can perform machine learning over the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDA8PosrA-9V"
      },
      "source": [
        "## Setup\n",
        "Check if PyTorch is properly installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntuPVat_BAf1"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fko_2wSKYlun"
      },
      "source": [
        "## PyTorch tensor basics\n",
        "\n",
        "We can generate PyTorch tensor with all zeros, ones or random values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ySw3m-A9qF"
      },
      "source": [
        "# Generate 3 x 4 tensor with all ones\n",
        "ones = torch.ones(3, 4)\n",
        "print(ones)\n",
        "\n",
        "# Generate 3 x 4 tensor with all zeros\n",
        "zeros = torch.zeros(3, 4)\n",
        "print(zeros)\n",
        "\n",
        "# Generate 3 x 4 tensor with random values on the interval [0, 1)\n",
        "random_tensor = torch.rand(3, 4)\n",
        "print(random_tensor)\n",
        "\n",
        "# Get the shape of the tensor\n",
        "print(ones.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8mp66eHBxWC"
      },
      "source": [
        "PyTorch tensors contains elements for a single data type, the `dtype`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQiOvKJJBwq4"
      },
      "source": [
        "# Create a 3 x 4 tensor with all 32-bit floating point zeros\n",
        "zeros = torch.zeros(3, 4, dtype=torch.float32)\n",
        "print(zeros.dtype)\n",
        "\n",
        "# Change the tensor dtype to 64-bit integer\n",
        "zeros = zeros.type(torch.long)\n",
        "print(zeros.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EfegIRDkk2"
      },
      "source": [
        "## Question 5: Get the edge list of the karate club network and transform it into `torch.LongTensor`. What is the `torch.sum` value of the `pos_edge_index` tensor? (5 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEtVxMFID3ZT"
      },
      "source": [
        "def graph_to_edge_list(G):\n",
        "  # TODO: Implement a function that returns the edge list of\n",
        "  # a nx.Graph. The returned edge_list should be a list of tuples\n",
        "  # where each tuple represents an edge between two nodes.\n",
        "\n",
        "  edge_list = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note:\n",
        "  ## Try to use simple networkx functions.\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return edge_list\n",
        "\n",
        "def edge_list_to_tensor(edge_list):\n",
        "  # TODO: Implement a function that transforms the edge_list to a\n",
        "  # tensor. The input edge_list is a list of tuples and the resulting\n",
        "  # tensor should have the shape [2 x len(edge_list)].\n",
        "\n",
        "  edge_index = torch.tensor([])\n",
        "\n",
        "  ############# Your code here ############\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return edge_index\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  pos_edge_list = graph_to_edge_list(G)\n",
        "  pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
        "  print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))\n",
        "  print(\"The pos_edge_index tensor has sum value {}\".format(torch.sum(pos_edge_index)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBL-ZmdHWqIu"
      },
      "source": [
        "## Question 6: Implement a function that samples negative edges. Here we define a negative edge between nodes $u$ and $v$ if there is no edge between $u$ and $v$ in the graph.\n",
        "\n",
        "## Then, write a short function to answer which edges (edge_1 to edge_5) can be negative edges in the karate club network? (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N8VT1f8-IJ8"
      },
      "source": [
        "import random\n",
        "\n",
        "def sample_negative_edges(G, num_neg_samples):\n",
        "  # TODO: Implement a function that returns a list of RANDOM negative edges.\n",
        "  # The number of sampled negative edges is num_neg_samples. You do not\n",
        "  # need to consider the corner case when the number of possible negative edges\n",
        "  # is less than num_neg_samples. It should be ok as long as your implementation \n",
        "  # works on the karate club network. \n",
        "  # \n",
        "  # In this implementation, self loops should not be considered as\n",
        "  # either positive or negative edge. Also, notice that \n",
        "  # the karate club network is an undirected graph; if (0, 1) is a positive \n",
        "  # edge, do you think (1, 0) can be a negative one?\n",
        "\n",
        "  # Set the random number generator seed\n",
        "  random.seed(1)\n",
        "\n",
        "  neg_edge_list = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## NOTE:\n",
        "  ## Remeber to sample negative edges randomly!\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return neg_edge_list\n",
        "\n",
        "def check_negative_edge(G, edge):\n",
        "  # TODO: Implement a function that returns whether a given edge \n",
        "  # is a negative edge within the graph G.\n",
        "\n",
        "  is_negative_edge = False\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## NOTE:\n",
        "  ## Check the definition of a negative edge from the question.\n",
        "  \n",
        "  \n",
        "  #########################################\n",
        "\n",
        "  return is_negative_edge\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  # Sample 78 negative edges\n",
        "  neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
        "\n",
        "  # Transform the negative edge list to tensor\n",
        "  neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
        "  print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n",
        "\n",
        "  # Which of following edges can be negative ones?\n",
        "  edge_1 = (7, 1)\n",
        "  edge_2 = (1, 33)\n",
        "  edge_3 = (33, 22)\n",
        "  edge_4 = (0, 4)\n",
        "  edge_5 = (4, 2)\n",
        "\n",
        "  for u, v in [edge_1, edge_2, edge_3, edge_4, edge_5]:\n",
        "    print ((u, v), check_negative_edge(G, (u, v)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9Q-a-9qGsw"
      },
      "source": [
        "# 3) Node Emebedding Learning\n",
        "\n",
        "Finally, we complete our first learning algorithm on graphs: a node embedding model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDBxRQcZ_dUH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnqn9H6s_ehX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gomAf8vxq0R"
      },
      "source": [
        "To write our own node embedding model, we heavily utilize the [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) module in PyTorch. Let us first explore how to use `nn.Embedding`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRiWGuLAx5yx"
      },
      "source": [
        "# Initialize an embedding layer.\n",
        "# Suppose we want to have embedding for 4 items (e.g., nodes).\n",
        "# Each item is represented by an 8 dimensional vector.\n",
        "\n",
        "emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n",
        "print('Sample embedding layer: {}'.format(emb_sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS9qQfeujEVh"
      },
      "source": [
        "We can select items from the embedding matrix by using Tensor indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AGIfP4QEDr8"
      },
      "source": [
        "# Select an embedding in emb_sample\n",
        "id = torch.LongTensor([1])\n",
        "print(emb_sample(id))\n",
        "\n",
        "# Select multiple embeddings\n",
        "ids = torch.LongTensor([1, 3])\n",
        "print(emb_sample(ids))\n",
        "\n",
        "# Get the shape of the embedding weight matrix\n",
        "shape = emb_sample.weight.data.shape\n",
        "print(shape)\n",
        "\n",
        "# Overwrite the weight to tensor with all ones\n",
        "emb_sample.weight.data = torch.ones(shape)\n",
        "\n",
        "# Let's check if the emb is indeed initilized\n",
        "ids = torch.LongTensor([0, 3])\n",
        "print(emb_sample(ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MjBuDKaKIsM"
      },
      "source": [
        "Now, it's your time to create a node embedding matrix for our graph!\n",
        "- We want to have **16 dimensional** vectors for each node in the karate club network.\n",
        "- We initalize the matrix using a **uniform distribution**, in the range of $[0, 1)$. We suggest using [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMszSwRPKGn1"
      },
      "source": [
        "# Please do not change / reset the random seed\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def create_node_emb(num_node=34, embedding_dim=16):\n",
        "  # TODO: Implement a function that creates the node embedding matrix.\n",
        "  # Return a torch.nn.Embedding layer. You do not need to change \n",
        "  # the values of num_node and embedding_dim. The weight matrix of the returned \n",
        "  # layer should be initialized under uniform distribution. \n",
        "\n",
        "  emb = None\n",
        "\n",
        "  ############# Your code here ############\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return emb\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  emb = create_node_emb()\n",
        "  ids = torch.LongTensor([0, 3])\n",
        "\n",
        "  # Print the embedding layer\n",
        "  print(\"Embedding: {}\".format(emb))\n",
        "\n",
        "  # An example that gets the embeddings for node 0 and 3\n",
        "  print(emb(ids))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QfoANibTzyh"
      },
      "source": [
        "## Visualize the initial node embeddings\n",
        "One good way to understand an embedding matrix, is to visualize it in a 2D space.\n",
        "Here, we have implemented an embedding visualization function for you.\n",
        "We first do PCA to reduce the dimensionality of embeddings to a 2D space.\n",
        "Then, we visualize each point, colored by the community it belongs to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LCoIkarhfYD"
      },
      "source": [
        "def visualize_emb(emb):\n",
        "  X = emb.weight.data.numpy()\n",
        "  pca = PCA(n_components=2)\n",
        "  components = pca.fit_transform(X)\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  club1_x = []\n",
        "  club1_y = []\n",
        "  club2_x = []\n",
        "  club2_y = []\n",
        "  for node in G.nodes(data=True):\n",
        "    if node[1]['club'] == 'Mr. Hi':\n",
        "      club1_x.append(components[node[0]][0])\n",
        "      club1_y.append(components[node[0]][1])\n",
        "    else:\n",
        "      club2_x.append(components[node[0]][0])\n",
        "      club2_y.append(components[node[0]][1])\n",
        "  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
        "  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the initial random embeddding\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  visualize_emb(emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQIyuEz9ANb2"
      },
      "source": [
        "## Question 7: Training your embeddings! Train your embedding model and see the best performance that you can get. You should experiment with changing a few of the hyper parameters to observe the effect on training. (10 Points)\n",
        "\n",
        "**NOTE**: There is no need to heavily hyper-parameter tune your model! We ask you to explore updateding a couple of hyper-parameters primarily to explore their potential effects. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDeQTNNxqH0j"
      },
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "def accuracy(pred, label):\n",
        "  # TODO: Implement the accuracy function. This function takes as input the \n",
        "  # pred tensor (the resulting tensor after sigmoid) and the label \n",
        "  # tensor (torch.LongTensor). Predicted values greater than 0.5 are \n",
        "  # classified as label 1. Else they are classified as label 0.\n",
        "  # The returned accuracy should be rounded to 4 decimal places. \n",
        "  # For example, accuracy 0.82956 will be rounded to 0.8296.\n",
        "\n",
        "  accu = 0.0\n",
        "\n",
        "  ############# Your code here ############\n",
        "\n",
        "\n",
        "  #########################################\n",
        "\n",
        "  return accu\n",
        "\n",
        "def train(emb, loss_fn, sigmoid, train_label, train_edge):\n",
        "  # TODO: Train the embedding layer here. You can also change epochs and \n",
        "  # learning rate. In general, you need to implement: \n",
        "  # (1) Get the embeddings of the nodes in train_edge\n",
        "  # (2) Dot product the embeddings between each node pair\n",
        "  # (3) Feed the dot product result into sigmoid\n",
        "  # (4) Feed the sigmoid output into the loss_fn\n",
        "  # (5) Print both loss and accuracy of each epoch \n",
        "  # (as a sanity check, the loss should decrease during training)\n",
        "\n",
        "  epochs = 500\n",
        "  learning_rate = 0.1\n",
        "\n",
        "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    ############# Your code here ############\n",
        "    \n",
        "    pass\n",
        "\n",
        "    #########################################\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  loss_fn = nn.BCELoss()\n",
        "  sigmoid = nn.Sigmoid()\n",
        "\n",
        "  # Generate the positive and negative labels\n",
        "  pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "  neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "\n",
        "  # Concat positive and negative labels into one tensor\n",
        "  train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "\n",
        "  # Concat positive and negative edges into one tensor\n",
        "  # Since the network is very small, we do not split the edges into val/test sets\n",
        "  train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "  print (train_edge)\n",
        "\n",
        "  train(emb, loss_fn, sigmoid, train_label, train_edge)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62LuURV24Jjk"
      },
      "source": [
        "## **Saving Your Model Predictions**!\n",
        "After you have successfully trained your embedding model, run the cell below to save your model's predictions over the training data. The function below will generate and save a csv file called *model_predictions.csv* to the local colab files folder. This folder can be accessed by clicking the *Folder* icon on the left panel underneath the *Table of contents*, *Find and replace*, and *Code snippets* icons. \n",
        "\n",
        "When submitting this colab you will have to download your model's predictions and submit them along with your colab ipython notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jjz5J1W4GLj"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def save_model_results(emb_model, train_label, train_edge):\n",
        "  \"\"\"\n",
        "    Helper function to save the model predictions and data\n",
        "    labels to a csv file for submission.\n",
        "  \"\"\"\n",
        "  sigmoid = nn.Sigmoid()\n",
        "\n",
        "  # Generate model predictions\n",
        "  embedding_u = emb_model(train_edge[0])\n",
        "  embedding_v = emb_model(train_edge[1])\n",
        "  product = embedding_u * embedding_v\n",
        "\n",
        "  pred = torch.sum(product, dim=1)\n",
        "  pred = sigmoid(pred).detach()\n",
        "\n",
        "  # Create a pandas datafram with columns\n",
        "  # model_pred | binary_pred | label\n",
        "  data = {}\n",
        "  data['model_pred'] = pred\n",
        "  data['binary_pred'] = np.where(pred > 0.5, 1.0, 0.0)\n",
        "  data['label'] = train_label.detach()\n",
        "\n",
        "  df = pd.DataFrame(data=data)\n",
        "  # Save to csv\n",
        "  df.to_csv('model_predictions.csv', sep=',', index=False)\n",
        "\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  save_model_results(emb, train_label, train_edge)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX2PSXnTDiNi"
      },
      "source": [
        "## Visualize the final node embeddings\n",
        "Now we can visually compare our embeddings with the embeddings before training. After training, you should oberserve that the two classes are more evidently separated. \n",
        "This is a great sanity check for your implementation, in addition to tracking the model's accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtNgl4VhYKow"
      },
      "source": [
        "# Visualize the final learned embedding\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  visualize_emb(emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTNyrAoSVeq9"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_E7J_GkVhY_"
      },
      "source": [
        "You will need to submit two files on Gradescope to complete this notebook. \n",
        "\n",
        "1.   Your completed *XCS224W_Colab1.ipynb*. From the \"File\" menu select \"Download .ipynb\" to save a local copy of your completed Colab. \n",
        "2.   Your model predictions. Open up the local Colab file folder (by selecting the Folder icon on the left panel) and download *model_predictions.csv* \n",
        "\n",
        "For submitting your work, zip the files downloaded in steps 1 and 2 above and submit to gradescope. **NOTE:** DO NOT rename any of the downloaded files. The file names should be *XCS224W_Colab1.ipynb* and *model_predictions.csv*.\n",
        "\n"
      ]
    }
  ]
}